{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Wtsr02OvU4e"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.nn import GCNConv, SAGEConv, GATConv, GINConv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load your dataset (replace with your dataset path)\n",
        "fake_df = pd.read_csv('/path/to/your/fake_news.csv')\n",
        "true_df = pd.read_csv('/path/to/your/true_news.csv')\n",
        "\n",
        "# Add labels (0 = fake, 1 = true)\n",
        "fake_df['label'] = 0\n",
        "true_df['label'] = 1\n",
        "\n",
        "# Combine the datasets\n",
        "df = pd.concat([fake_df, true_df], ignore_index=True)\n",
        "\n",
        "# Here you will need to define how you construct the graph,\n",
        "# typically using TF-IDF or other features to build adjacency matrices for nodes (texts/articles)\n",
        "# This step assumes you have already constructed node features and edge indices for your graph\n",
        "# For illustration purposes, we will create some dummy features and edge indices\n",
        "# Replace this with actual graph construction logic.\n",
        "\n",
        "num_nodes = len(df)\n",
        "node_features = np.random.rand(num_nodes, 128)  # Example feature vector for each node (128-dim)\n",
        "edge_index = np.random.randint(0, num_nodes, (2, num_nodes * 5))  # Example random edges\n",
        "labels = df['label'].values\n",
        "\n",
        "# Split into train and test sets\n",
        "train_idx, test_idx = train_test_split(np.arange(num_nodes), test_size=0.2, random_state=42)\n",
        "train_labels, test_labels = labels[train_idx], labels[test_idx]\n",
        "\n",
        "# Create PyTorch geometric Data objects for train and test sets\n",
        "train_data = Data(x=torch.tensor(node_features[train_idx], dtype=torch.float),\n",
        "                  edge_index=torch.tensor(edge_index, dtype=torch.long),\n",
        "                  y=torch.tensor(train_labels, dtype=torch.long))\n",
        "\n",
        "test_data = Data(x=torch.tensor(node_features[test_idx], dtype=torch.float),\n",
        "                 edge_index=torch.tensor(edge_index, dtype=torch.long),\n",
        "                 y=torch.tensor(test_labels, dtype=torch.long))\n",
        "\n",
        "train_loader = DataLoader([train_data], batch_size=1, shuffle=True)\n",
        "test_loader = DataLoader([test_data], batch_size=1, shuffle=False)\n",
        "\n",
        "# Define the GNN model class (supports GCN, GraphSAGE, GAT, GIN)\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, model_type='gcn', input_dim=128, hidden_dim=64, output_dim=2):\n",
        "        super(GNN, self).__init__()\n",
        "\n",
        "        if model_type == 'gcn':\n",
        "            self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "            self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
        "        elif model_type == 'graphsage':\n",
        "            self.conv1 = SAGEConv(input_dim, hidden_dim)\n",
        "            self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
        "        elif model_type == 'gat':\n",
        "            self.conv1 = GATConv(input_dim, hidden_dim, heads=8)\n",
        "            self.conv2 = GATConv(hidden_dim * 8, hidden_dim)\n",
        "        elif model_type == 'gin':\n",
        "            self.conv1 = GINConv(torch.nn.Sequential(torch.nn.Linear(input_dim, hidden_dim),\n",
        "                                                     torch.nn.ReLU(),\n",
        "                                                     torch.nn.Linear(hidden_dim, hidden_dim)))\n",
        "            self.conv2 = GINConv(torch.nn.Sequential(torch.nn.Linear(hidden_dim, hidden_dim),\n",
        "                                                     torch.nn.ReLU(),\n",
        "                                                     torch.nn.Linear(hidden_dim, hidden_dim)))\n",
        "\n",
        "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # Apply the first graph convolution layer and activation function\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "\n",
        "        # Apply the second graph convolution layer and activation function\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "\n",
        "        # Apply global mean pooling to get a fixed-size representation\n",
        "        x = torch.mean(x, dim=0, keepdim=True)\n",
        "\n",
        "        # Pass the pooled representation to the final fully connected layer\n",
        "        out = self.fc(x)\n",
        "\n",
        "        return out\n",
        "\n",
        "# Choose the GNN model type: 'gcn', 'graphsage', 'gat', or 'gin'\n",
        "model_type = 'gcn'  # Change this to 'graphsage', 'gat', or 'gin'\n",
        "\n",
        "# Instantiate the GNN model\n",
        "model = GNN(model_type=model_type, input_dim=128, hidden_dim=64, output_dim=2)\n",
        "\n",
        "# Use GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Set up optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Helper function to calculate evaluation metrics\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    roc_auc = roc_auc_score(y_true, y_pred)\n",
        "    return accuracy, precision, recall, f1, roc_auc\n",
        "\n",
        "# Training function\n",
        "def train(model, data_loader, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data in tqdm(data_loader, desc=\"Training\"):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = F.cross_entropy(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(data_loader)\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(model, data_loader, device):\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(data_loader, desc=\"Evaluating\"):\n",
        "            data = data.to(device)\n",
        "            out = model(data)\n",
        "            pred = out.argmax(dim=1).cpu().numpy()\n",
        "            predictions.extend(pred)\n",
        "            true_labels.extend(data.y.cpu().numpy())\n",
        "    return predictions, true_labels\n",
        "\n",
        "# Collect results\n",
        "results = []\n",
        "\n",
        "# Training and evaluation loop\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "    # Training\n",
        "    train_loss = train(model, train_loader, optimizer, device)\n",
        "    print(f\"Training loss: {train_loss}\")\n",
        "\n",
        "    # Evaluation\n",
        "    test_predictions, test_true_labels = evaluate(model, test_loader, device)\n",
        "\n",
        "    # Calculate metrics\n",
        "    test_acc, test_prec, test_rec, test_f1, test_roc_auc = calculate_metrics(test_true_labels, test_predictions)\n",
        "\n",
        "    # Log parameter count\n",
        "    num_params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "    # Collect results\n",
        "    results.append({\n",
        "        'Epoch': epoch + 1,\n",
        "        'Num Parameters': num_params,\n",
        "        'Test Accuracy': test_acc,\n",
        "        'Test Precision': test_prec,\n",
        "        'Test Recall': test_rec,\n",
        "        'Test F1': test_f1,\n",
        "        'Test ROC-AUC': test_roc_auc\n",
        "    })\n",
        "\n",
        "# Convert results to DataFrame and save\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv('/path/to/save/your_gnn_results.csv', index=False)\n",
        "\n",
        "# Print the results\n",
        "print(results_df)\n"
      ]
    }
  ]
}